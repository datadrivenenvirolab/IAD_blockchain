{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hoovers scraper 2020\n",
    "#### Zhi Yi Yeo\n",
    "\n",
    "Updating Hoovers scraper for 2020, since the database has been changed as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization \n",
    "import requests, pickle, time\n",
    "from urllib.parse import urljoin\n",
    "from multiprocessing.pool import ThreadPool, Pool\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import threading\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data that needs to be scraped \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>iso</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>country</th>\n",
       "      <th>GICS_Sector_Name</th>\n",
       "      <th>GICS_Sub_Industry_Name</th>\n",
       "      <th>account_id</th>\n",
       "      <th>target_year</th>\n",
       "      <th>raw_commitment</th>\n",
       "      <th>target_scope</th>\n",
       "      <th>...</th>\n",
       "      <th>total_scope1_emissions</th>\n",
       "      <th>ghg_emissions_inventory_year</th>\n",
       "      <th>total_scope2_emissions_market_based</th>\n",
       "      <th>total_scope2_emissions_location_based</th>\n",
       "      <th>total_scope3_emissions</th>\n",
       "      <th>net_zero</th>\n",
       "      <th>data_source</th>\n",
       "      <th>revenue</th>\n",
       "      <th>employees</th>\n",
       "      <th>revenue_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2A</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Energy utility networks, Non-energy utilities,...</td>\n",
       "      <td>Power generation</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>A2A has set specific goals to help reduce the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CDPCompanies2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD$ M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2A</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Energy utility networks, Non-energy utilities,...</td>\n",
       "      <td>Power generation</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>The definitive project will see the replacemen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CDPCompanies2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD$ M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2A</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Energy utility networks, Non-energy utilities,...</td>\n",
       "      <td>Power generation</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>A2A has set specific goals to develop solution...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CDPCompanies2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD$ M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2A</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Energy utility networks, Non-energy utilities,...</td>\n",
       "      <td>Power generation</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>A2A evaluate the natural gas dispersed from ro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CDPCompanies2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD$ M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2A</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Energy utility networks, Non-energy utilities,...</td>\n",
       "      <td>Power generation</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>In a process of setting a target for decarboni...</td>\n",
       "      <td>Scope 1</td>\n",
       "      <td>...</td>\n",
       "      <td>7491395.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>109807.0</td>\n",
       "      <td>Question not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>CDPCompanies2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD$ M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  iso entity_type country  \\\n",
       "0  A2A  ITA     Company   Italy   \n",
       "1  A2A  ITA     Company   Italy   \n",
       "2  A2A  ITA     Company   Italy   \n",
       "3  A2A  ITA     Company   Italy   \n",
       "4  A2A  ITA     Company   Italy   \n",
       "\n",
       "                                    GICS_Sector_Name GICS_Sub_Industry_Name  \\\n",
       "0  Energy utility networks, Non-energy utilities,...       Power generation   \n",
       "1  Energy utility networks, Non-energy utilities,...       Power generation   \n",
       "2  Energy utility networks, Non-energy utilities,...       Power generation   \n",
       "3  Energy utility networks, Non-energy utilities,...       Power generation   \n",
       "4  Energy utility networks, Non-energy utilities,...       Power generation   \n",
       "\n",
       "   account_id  target_year                                     raw_commitment  \\\n",
       "0        87.0       2023.0  A2A has set specific goals to help reduce the ...   \n",
       "1        87.0       2023.0  The definitive project will see the replacemen...   \n",
       "2        87.0       2023.0  A2A has set specific goals to develop solution...   \n",
       "3        87.0       2023.0  A2A evaluate the natural gas dispersed from ro...   \n",
       "4        87.0       2030.0  In a process of setting a target for decarboni...   \n",
       "\n",
       "  target_scope      ...       total_scope1_emissions  \\\n",
       "0          NaN      ...                          NaN   \n",
       "1          NaN      ...                          NaN   \n",
       "2          NaN      ...                          NaN   \n",
       "3          NaN      ...                          NaN   \n",
       "4      Scope 1      ...                    7491395.0   \n",
       "\n",
       "   ghg_emissions_inventory_year total_scope2_emissions_market_based  \\\n",
       "0                           NaN                                 NaN   \n",
       "1                           NaN                                 NaN   \n",
       "2                           NaN                                 NaN   \n",
       "3                           NaN                                 NaN   \n",
       "4                    2018-12-31                            109807.0   \n",
       "\n",
       "   total_scope2_emissions_location_based  total_scope3_emissions net_zero  \\\n",
       "0                                    NaN                     NaN        0   \n",
       "1                                    NaN                     NaN        0   \n",
       "2                                    NaN                     NaN        0   \n",
       "3                                    NaN                     NaN        0   \n",
       "4                Question not applicable                     NaN        1   \n",
       "\n",
       "        data_source  revenue employees revenue_units  \n",
       "0  CDPCompanies2019      NaN       NaN        USD$ M  \n",
       "1  CDPCompanies2019      NaN       NaN        USD$ M  \n",
       "2  CDPCompanies2019      NaN       NaN        USD$ M  \n",
       "3  CDPCompanies2019      NaN       NaN        USD$ M  \n",
       "4  CDPCompanies2019      NaN       NaN        USD$ M  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdp = pd.read_csv('~/Documents/Yale-NUS/Data-Driven Yale/Global Climate Action 2020/Net Zero/Companies/CDP_companies_nz_revenue_to_scrape_27Aug.csv',\n",
    "                 encoding = \"UTF-8\")\n",
    "cdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>iso</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2A</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ABN Amro Holding</td>\n",
       "      <td>NLD</td>\n",
       "      <td>Company</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AccorHotels</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Company</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ADLER &amp; ALLAN</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Company</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Adobe, Inc.</td>\n",
       "      <td>USA</td>\n",
       "      <td>Company</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  iso entity_type                   country\n",
       "0                A2A  ITA     Company                     Italy\n",
       "10  ABN Amro Holding  NLD     Company               Netherlands\n",
       "15       AccorHotels  FRA     Company                    France\n",
       "17     ADLER & ALLAN  GBR     Company            United Kingdom\n",
       "19       Adobe, Inc.  USA     Company  United States of America"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the names for scraping \n",
    "company_names = cdp[['name', 'iso', 'entity_type', 'country']]\n",
    "company_names = company_names.drop_duplicates()\n",
    "company_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Driver for scraper\n",
    "\n",
    "Because the data we need is also hidden behind a paywall (which NUS/YNC Accounts have access to), we need to login to our student/staff account for the scraper to work \n",
    "\n",
    "This part of the code sets up the driver for that. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use chrome, will need to ensure that chromedriver is in the path\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://linc.nus.edu.sg/record=b2679651\")\n",
    "elem = driver.find_element_by_link_text(\"D&B Hoovers (formerly known as D&B Business Browser)\")\n",
    "elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your username and password here to send over selenium, or alt tab over to the opened browser to key in manually\n",
    "username = \"test\"\n",
    "password = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in progress - better to sign in manually\n",
    "#user = driver.find_element_by_name(\"user\")\n",
    "#pw = driver.find_element_by_name(\"pass\")\n",
    "\n",
    "#user.send_keys(username)\n",
    "#pw.send_keys(password)\n",
    "\n",
    "#driver.find_element_by_css_selector(\"input[type='submit']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Scraping \n",
    "\n",
    "After signing in, we can start searching for companies and scraping data.\n",
    "\n",
    "We start with writing some helper functions to get the data from the page, use those helper functions to parse the different pages and get the data we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def login_check(url):\n",
    "    \n",
    "def get_actor(container):\n",
    "    # Get soup\n",
    "    soup = BeautifulSoup(container.get_attribute('outerHTML'), 'lxml')\n",
    "    # Name, sector, and location are in every actor, so no need for checks \n",
    "    name = soup.find(attrs={'class':'clickable'}).text\n",
    "    sector = soup.find(attrs={'class':'large-black-text'}).text\n",
    "    location = re.sub('\\s', '', soup.find(attrs={'class':'location'}).text)\n",
    "    # For the others (revenue, employees, etc.) it is not guaranteed the data is present\n",
    "    # so need to check \n",
    "    if soup.find(attrs={'class':'sales black'}) is not None:\n",
    "        revenue = soup.find(attrs={'class':'sales black'}).text.replace('\\n\\xa0\\n\\n', '')\n",
    "    else:\n",
    "        revenue = 'NA'\n",
    "    labels = []\n",
    "    for label in soup.find_all(attrs={'class': 'data-label'}):\n",
    "        labels.append(re.sub('\\n|\\xa0|  |•', '', label.text))\n",
    "    labels = '; '.join(labels)\n",
    "    # Now check for the different fields in labels and scrape whatever we can find \n",
    "    # Check for employees and assets \n",
    "    if bool(re.search(\"Employees \\(This Site\\)\", labels)):\n",
    "        employees_local = re.sub(\".*?Employees \\(This Site\\):([0-9,\\\\.kMB]+).*\", '\\\\1', labels)\n",
    "    else:\n",
    "        employees_local = 'NA'\n",
    "    if bool(re.search(\"Employees \\(All Sites\\)\", labels)):\n",
    "        employees_all = re.sub(\".*?Employees \\(All Sites\\):([0-9,\\\\.kMB]+).*\", '\\\\1', labels)\n",
    "    else:\n",
    "        employees_all = 'NA'\n",
    "    if bool(re.search(\"Assets\", labels)):\n",
    "        assets = re.sub(\".*?Assets:([0-9\\\\.MB]+).*\", '\\\\1', labels)\n",
    "    else: \n",
    "        assets = 'NA'\n",
    "            \n",
    "    actor_data = pd.DataFrame({'name':name, 'sector':sector, 'location':location,\n",
    "                               'revenue':revenue, 'employees_local':employees_local,\n",
    "                               'employees_all': employees_all, 'assets':assets},\n",
    "                             index = [0])\n",
    "    return actor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    # Parse info on page\n",
    "    # Check if any results returned first \n",
    "    num_results = driver.find_elements_by_class_name('js-total-results.total-count-number')[0].text\n",
    "    if int(num_results.replace(',', '')) == 0:\n",
    "        return\n",
    "    actors = driver.find_elements_by_class_name('container-fluid')\n",
    "    df = []\n",
    "    for actor in actors:\n",
    "        df.append(get_actor(actor))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Scraping loop \n",
    "\n",
    "Incorporate error handling so that not everything breaks if there are any errors. \n",
    "\n",
    "Also periodically save files so that I won't cry if everything breaks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names = company_names.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 106/1274 [13:09<2:21:45,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Eneco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 428/1274 [53:07<1:41:06,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Nos SGPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 440/1274 [54:38<1:49:10,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Iberia Lineas Aereas de Espana SA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 455/1274 [56:28<1:37:39,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for FullCycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 541/1274 [1:07:25<1:36:48,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Marlin Communications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 588/1274 [1:13:17<1:27:08,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Ionica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 616/1274 [1:16:43<1:15:52,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Pela\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 677/1274 [1:24:08<1:10:51,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Smart Air\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 769/1274 [1:35:17<1:02:09,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Palm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 889/1274 [1:49:30<42:45,  6.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Twist Sa | Sweet Rebels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1073/1274 [2:11:56<23:51,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1097/1274 [2:14:48<20:42,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Aber Food Surplus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 1100/1274 [2:15:15<24:48,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for African Bronze Honey Company\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1124/1274 [2:18:15<19:40,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for De Smaakspecialist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1128/1274 [2:18:45<19:15,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Dolphin Blue Inc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1184/1274 [2:25:34<10:59,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for New Hope Ecotech | eureciclo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1198/1274 [2:27:08<08:46,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for PATHFINDER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1236/1274 [2:31:44<04:34,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for Up Marketing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1241/1274 [2:32:22<04:07,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for VIANOVA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1274/1274 [2:36:28<00:00,  7.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# Main Scraping loop \n",
    "stem =  'https://app.avention.com/search/company?q='\n",
    "main = []\n",
    "errors = []\n",
    "for i in tqdm(range(company_names.shape[0])):\n",
    "    # Save every 300 names get scraped\n",
    "    if i % 300 == 0 & i != 0:\n",
    "        main_rm = [i for i in main if i] \n",
    "        main_export = pd.concat(flatten(main_rm))\n",
    "        main_export.to_csv('~/Documents/Yale-NUS/Data-Driven Yale/Global Climate Action 2020/Net Zero/Companies/hoovers_revenue_upto' + i + 'actors.csv',\n",
    "                          encoding = 'UTF-8')\n",
    "    try: \n",
    "        url = stem + company_names['name'][i]\n",
    "        main.append(get_page(url))\n",
    "    except:\n",
    "        print('Error scraping for ' + company_names['name'][i])\n",
    "        errors.append(company_names['name'][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 9/19 [01:13<01:21,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for AKF INTERNATIONAL CORP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 15/19 [01:59<00:31,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping for AMCOL(TIANJIN) INDUSTRIAL MINERALS CO., LTD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:28<00:00,  7.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# Try scraping for errors again\n",
    "stem =  'https://app.avention.com/search/company?q='\n",
    "for i in tqdm(range(len(errors))):\n",
    "    try: \n",
    "        url = stem + errors[i]\n",
    "        main.append(get_page(url))\n",
    "    except:\n",
    "        print('Error scraping for ' + errors[i])\n",
    "        errors.append(errors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "main_rm = [i for i in main if i] \n",
    "main_df = pd.concat(flatten(main_rm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13148, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv('~/Documents/Yale-NUS/Data-Driven Yale/Global Climate Action 2020/Net Zero/Companies/hoovers_revenue_full_28Aug.csv',\n",
    "           encoding = 'UTF-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
