{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fortune500 Global Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps to get the link to the raw data:\n",
    "\n",
    "1) Go to the website with all the companies listed - [Current Link](https://fortune.com/global500/search/)\n",
    "\n",
    "2) Inspect the page, and go to the `Network` Tab\n",
    "\n",
    "3) Refresh the page\n",
    "\n",
    "4) Sort the scripts by size, and open the script with the raw data. It should be the largest one (around 1 mb)\n",
    "\n",
    "5) Copy the link, __run the next cell__, and paste the link to get the scraped data in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests, csv, ast\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.packages.urllib3.exceptions import *\n",
    "\n",
    "link = input(\"What is the link for the data? \")\n",
    "page = requests.get(link)\n",
    "text = BeautifulSoup(page.content, 'lxml').find(\"p\").text\n",
    "data = ast.literal_eval(text)\n",
    "\n",
    "final = []\n",
    "\n",
    "for x in data:\n",
    "    if x['key'] == 'items':\n",
    "        for row in x['items']:\n",
    "            # Choosing the categories that we want to include\n",
    "            new = {'rank': '', 'name': '', 'sector': '', 'fg500_country': '', 'fg500_revenues': '', 'fg500_profits': '', 'assets': '', 'fg500_employees': ''}\n",
    "            for item in row['fields']:\n",
    "                if item['key'] in list(new.keys()):\n",
    "                    try:\n",
    "                        new[item['key']] = int(item['value'])\n",
    "                    except:\n",
    "                        new[item['key']] = item['value']\n",
    "            final.append(new)\n",
    "                     \n",
    "output = sorted(final, key = lambda i: i['rank'])\n",
    "\n",
    "with open(\"fortune500global_scraped2020.csv\", 'w', newline='', encoding = 'utf-8-sig') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
    "    header = ['Rank', 'Name', 'Sector', 'Country', 'Revenues ($M)', 'Profits ($M)', 'Assets ($M)', 'Employees']\n",
    "    spamwriter.writerow(header)\n",
    "    for x in output:\n",
    "        row = list(x.values())\n",
    "        spamwriter.writerow(row)\n",
    "        \n",
    "print()\n",
    "print(\"File has been created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links for data scraped in past years\n",
    "\n",
    "__2020:__ https://content.fortune.com/wp-json/irving/v1/data/franchise-search-results?list_id=2866578&token=Zm9ydHVuZTpCcHNyZmtNZCN5SndjWkkhNHFqMndEOTM="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
